input {
    stdin {
    }
    jdbc {
      # mysql jdbc connection string to our backup databse
      jdbc_connection_string => "jdbc:mysql://localhost:3306/es"
      # the user we wish to excute our statement as
      jdbc_user => "root"
      jdbc_password => "123456"
      # the path to our downloaded jdbc driver
      jdbc_driver_library => "mysql-connector-java-8.0.16.jar"
      # the name of the driver class for mysql
      jdbc_driver_class => "com.mysql.jdbc.Driver"
      jdbc_paging_enabled => "true"
      jdbc_page_size => "50000"
      statement_filepath => "jdbc.sql"
         # 需要记录查询结果某字段的值时，此字段为true，否则默认tracking_column为timestamp的值；
         use_column_value => true
         # 是否将字段名转换为小写，默认true（如果有数据序列化、反序列化需求，建议改为false）；
         lowercase_column_names => false
         # 需要记录的字段，用于增量同步，需是数据库字段
         tracking_column => id
         # Value can be any of: numeric,timestamp，Default value is "numeric"
         tracking_column_type => numeric
         # record_last_run上次数据存放位置；
         record_last_run => true
         #上一个sql_last_value值的存放文件路径, 必须要在文件中指定字段的初始值
         last_run_metadata_path => "F:\ES\logstash-5.5.1\config\station_parameter.txt"
         # 是否清除last_run_metadata_path的记录，需要增量同步时此字段必须为false；
         clean_run => false
      schedule => "* * * * *"
      type => "jdbc"
    }
}

filter {
    json {
        source => "message"
        remove_field => ["message"]
    }
}

output {
    elasticsearch {
        hosts => "localhost:9200"
        index => "mysql01"
        document_id => "%{id}"
    }
    stdout {
        codec => json_lines
    }
}